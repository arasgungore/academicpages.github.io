---
title: "Explainable AI for engineering design: A unified approach of systems engineering and component-based deep learning"
collection: publications
permalink: /publication/2021-08-30-ExplainableAI
excerpt: '
Introducing a groundbreaking intersection of systems engineering and deep learning: our component-based, data-driven model. This unique approach not only adapts to the inherent structure of systems engineering but also prioritizes domain knowledge, ensuring that our models are interpretable and aligned with engineering principles. Dive deep into our innovative methodology that bridges the gap between the vast potential of AI and the meticulous precision of engineering design.
'
date: 2021-08-30
venue: 'Arxiv'
paperurl: ''
citation: '<i>	Geyer, P., Singh, M.M. & Chen, X., (2021). Explainable AI for engineering design: A unified approach of systems engineering and component-based deep learning. arXiv preprint arXiv:2108.13836.</i>'
---

**Abstract**: <br>
Data-driven models created by machine learning gain in importance in all fields of design and engineering. They have high potential to assists decision-makers in creating novel artefacts with better performance and sustainability. However, limited generalization and the black-box nature of these models lead to limited explainability and reusability. These drawbacks provide significant barriers retarding adoption in engineering design. To overcome this situation, we propose a component-based approach to create partial component models by machine learning (ML). This component-based approach aligns deep learning to systems engineering (SE). By means of the example of energy efficient building design, we first demonstrate better generalization of the component-based method by analyzing prediction accuracy outside the training data. Especially for representative designs different in structure, we observe a much higher accuracy (R2 = 0.94) compared to conventional monolithic methods (R2 = 0.71). Second, we illustrate explainability by exemplary demonstrating how sensitivity information from SE and rules from low-depth decision trees serve engineering. Third, we evaluate explainability by qualitative and quantitative methods demonstrating the matching of preliminary knowledge and data-driven derived strategies and show the correctness of activations at component interfaces compared to white-box simulation results (envelope components: R2 = 0.92..0.99; zones: R2 = 0.78..0.93). The key for component-based explainability is that activations at interfaces between the components are interpretable engineering quantities. In this way, the hierarchical component system forms a deep neural network (DNN) that a priori integrates information for engineering explainability.<br>
![image](https://user-images.githubusercontent.com/106488602/217064290-a9f7ccf5-8b55-4c9a-a852-0c76c62d8722.png)<br>

[[Download paper here]](https://arxiv.org/abs/2108.13836)

**Citation**:<i> Geyer, P., Singh, M.M. & Chen, X., (2021). Explainable AI for engineering design: A unified approach of systems engineering and component-based deep learning. arXiv preprint arXiv:2108.13836.</i>
